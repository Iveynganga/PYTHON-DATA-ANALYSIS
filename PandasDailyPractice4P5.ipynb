{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iveynganga/PYTHON-DATA-ANALYSIS/blob/main/PandasDailyPractice4P5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdxbIRwZrVgO"
      },
      "source": [
        "# Wind Statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fobyLu7rVgQ"
      },
      "source": [
        "### Introduction:\n",
        "\n",
        "The data have been modified to contain some missing values, identified by NaN.  \n",
        "Using pandas should make this exercise\n",
        "easier, in particular for the bonus question.\n",
        "\n",
        "You should be able to perform all of these operations without using\n",
        "a for loop or other looping construct.\n",
        "\n",
        "\n",
        "1. The data in 'wind.data' has the following format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0V1Sk4ArVgR",
        "outputId": "af3c5827-f3b1-419d-8042-2bc4a3c0b832"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nYr Mo Dy   RPT   VAL   ROS   KIL   SHA   BIR   DUB   CLA   MUL   CLO   BEL   MAL\\n61  1  1 15.04 14.96 13.17  9.29   NaN  9.87 13.67 10.25 10.83 12.58 18.50 15.04\\n61  1  2 14.71   NaN 10.83  6.50 12.62  7.67 11.50 10.04  9.79  9.67 17.54 13.83\\n61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 11.25   NaN  8.50  7.67 12.75 12.71\\n'"
            ]
          },
          "execution_count": 434,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Yr Mo Dy   RPT   VAL   ROS   KIL   SHA   BIR   DUB   CLA   MUL   CLO   BEL   MAL\n",
        "61  1  1 15.04 14.96 13.17  9.29   NaN  9.87 13.67 10.25 10.83 12.58 18.50 15.04\n",
        "61  1  2 14.71   NaN 10.83  6.50 12.62  7.67 11.50 10.04  9.79  9.67 17.54 13.83\n",
        "61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 11.25   NaN  8.50  7.67 12.75 12.71\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZox9yZerVgS"
      },
      "source": [
        "   The first three columns are year, month and day.  The\n",
        "   remaining 12 columns are average windspeeds in knots at 12\n",
        "   locations in Ireland on that day.   \n",
        "\n",
        "   More information about the dataset go [here](wind.desc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "PEuUikn2rVgT"
      },
      "source": [
        "### Step 1. Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BACzvqV3rVgT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbYrlwZdrVgT"
      },
      "source": [
        "### Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data\"\n",
        "\n",
        "wind_data = pd.read_csv(url, sep=\"\\s+\", parse_dates=[[0, 1, 2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqmRVBawr_1J",
        "outputId": "7c00e133-9373-4dc5-81d5-db1d6e04af3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-8d45a9d1a217>:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  wind_data = pd.read_csv(url, sep=\"\\s+\", parse_dates=[[0, 1, 2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKVpo-P8rVgT"
      },
      "source": [
        "### Step 3. Assign it to a variable called data and replace the first 3 columns by a proper datetime index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F4sI_furVgT",
        "outputId": "929862b2-c7c3-4484-f504-e03b3d6f38f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-a7dd6b1bcd61>:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data = pd.read_csv(url, sep=\"\\s+\", parse_dates=[[0, 1, 2]])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data\"\n",
        "\n",
        "data = pd.read_csv(url, sep=\"\\s+\", parse_dates=[[0, 1, 2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkRPrYVqrVgT"
      },
      "source": [
        "### Step 4. Year 2061? Do we really have data from this year? Create a function to fix it and apply it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmiWcD5SrVgU",
        "outputId": "37942be6-b05b-4b38-ce21-c6e92203b801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-8a1cd4227da5>:14: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data = pd.read_csv(url, sep=\"\\s+\", parse_dates=[[0, 1, 2]])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def fix_year(dt):\n",
        "    if dt.year > 2000:\n",
        "        return dt - pd.DateOffset(years=100)\n",
        "    else:\n",
        "        return dt\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data\"\n",
        "\n",
        "data = pd.read_csv(url, sep=\"\\s+\", parse_dates=[[0, 1, 2]])\n",
        "\n",
        "data.index = data['Yr_Mo_Dy'].map(fix_year)\n",
        "data.drop('Yr_Mo_Dy', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrSSCzePrVgU"
      },
      "source": [
        "### Step 5. Set the right dates as the index. Pay attention at the data type, it should be datetime64[ns]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZILMv5l9rVgU",
        "outputId": "09625251-cae9-4abc-a260-939787678671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-17b0fe9f9ce6>:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data = pd.read_csv(url, sep=\"\\s+\", parse_dates=[[0, 1, 2]], index_col=0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def fix_year(dt):\n",
        "    if dt.year > 2000:\n",
        "        return dt - pd.DateOffset(years=100)\n",
        "    else:\n",
        "        return dt\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data\"\n",
        "\n",
        "data = pd.read_csv(url, sep=\"\\s+\", parse_dates=[[0, 1, 2]], index_col=0)\n",
        "\n",
        "data.index = data.index.map(fix_year)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhDawtj2rVgU"
      },
      "source": [
        "### Step 6. Compute how many values are missing for each location over the entire record.  \n",
        "#### They should be ignored in all calculations below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6sFPtmirVgU"
      },
      "outputs": [],
      "source": [
        "missing_values_per_location = data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYTrIpyFrVgU"
      },
      "source": [
        "### Step 7. Compute how many non-missing values there are in total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "VOrUdeH7rVgU"
      },
      "outputs": [],
      "source": [
        "total_non_missing_values = data.count().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PJP33iArVgV"
      },
      "source": [
        "### Step 8. Calculate the mean windspeeds of the windspeeds over all the locations and all the times.\n",
        "#### A single number for the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4DWjfkZrVgV"
      },
      "outputs": [],
      "source": [
        "mean_windspeed = data.mean().mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2LbPRWHrVgV"
      },
      "source": [
        "### Step 9. Create a DataFrame called loc_stats and calculate the min, max and mean windspeeds and standard deviations of the windspeeds at each location over all the days\n",
        "\n",
        "#### A different set of numbers for each location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xdgGWupgrVgV"
      },
      "outputs": [],
      "source": [
        "loc_stats = data.describe().T[['min', 'max', 'mean', 'std']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhuE9sfsrVgV"
      },
      "source": [
        "### Step 10. Create a DataFrame called day_stats and calculate the min, max and mean windspeed and standard deviations of the windspeeds across all the locations at each day.\n",
        "\n",
        "#### A different set of numbers for each day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NIkNLAc7rVgV"
      },
      "outputs": [],
      "source": [
        "day_stats = pd.DataFrame({\n",
        "    'min': data.min(axis=1),\n",
        "    'max': data.max(axis=1),\n",
        "    'mean': data.mean(axis=1),\n",
        "    'std': data.std(axis=1)\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHNZHGLOrVgV"
      },
      "source": [
        "### Step 11. Find the average windspeed in January for each location.  \n",
        "#### Treat January 1961 and January 1962 both as January."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DdMocl_ZrVgV"
      },
      "outputs": [],
      "source": [
        "january_data = data[data.index.month == 1]\n",
        "\n",
        "average_windspeed_january = january_data.mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92ziM3iprVgV"
      },
      "source": [
        "### Step 12. Downsample the record to a yearly frequency for each location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CYrjC2oSrVgV"
      },
      "outputs": [],
      "source": [
        "yearly_data = data.resample('Y').mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEGOP3RSrVgW"
      },
      "source": [
        "### Step 13. Downsample the record to a monthly frequency for each location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UCEbHaBBrVgW"
      },
      "outputs": [],
      "source": [
        "monthly_data = data.resample('M').mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cR5qFsFrVgW"
      },
      "source": [
        "### Step 14. Downsample the record to a weekly frequency for each location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y5sPUZhrVgW"
      },
      "outputs": [],
      "source": [
        "weekly_data = data.resample('W').mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCaNhyofrVgW"
      },
      "source": [
        "### Step 15. Calculate the min, max and mean windspeeds and standard deviations of the windspeeds across all locations for each week (assume that the first week starts on January 2 1961) for the first 52 weeks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zRPQNk4WrVgW"
      },
      "outputs": [],
      "source": [
        "offset_index = data.index + pd.DateOffset(days=1)\n",
        "\n",
        "data_offset = data.copy()\n",
        "data_offset.index = offset_index\n",
        "\n",
        "weekly_data = data_offset.resample('W').mean()\n",
        "\n",
        "weekly_stats = weekly_data.head(52).agg(['min', 'max', 'mean', 'std'])\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}